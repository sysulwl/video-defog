场景深度   								scene depth
立体匹配   								stereo matching 
雾信息	   								fog information
光相干项(照片一致性项)，光密度测量   	photo-consistency term
散射效应   								scattering effects
先验消光拉普拉斯约束   					prior matting Laplacian constraint
细节保持平滑约束						detail-preserving smoothness constraint
MRF框架
辅助变量								auxiliary variables
迭代优化								optimized iteratively 
多视角立体								Multi-view stereo
图像对比度								image contrast

深度平滑								depth smoothness
表面细节								surface details
depth ordering
detail preserving smoothness
airlight-albedo
unsaturated color
multiple depth map approach
multi-view stereo (MVS) vision 
visibility
occlusions
consistency 
sensitivity
geometric coherence term
geometric constraints
characteristic artifacts
energy functions
 depth maps
 shrinking bias
 airlight
 maximizing local contrast
shading 
transmission functions
dark channe
boundary constraint
image fusion
photo-consistency term
  
atmospheric light    是什么  ， alpha是什么？
如何获取alpha ，  atomspheric light A呢。
首先


estTransmission  这个函数，生成了A之后，将im的r g b 三维点除以A， 再简单计算得到alpha矩阵。这就是我们看到的第一张灰度图。

随后，进入拉普拉斯函数的研究。
  
有非常多的专业术语需要我们去搞懂，所以建议还是用英文去学习吧。 
首先，深度图是啥？————是不是我们传统理解的灰度图?
原来，深度就是离我们多远的这个概念，来决定一张图中的先后顺序。深度图像的每个像素点的灰度值可用于表征场景中某一点距离摄像机的远近

边缘检测的目的是标识数字图像中属性显著变化的点。图像属性中的显著变化通常反映了属性的重要变化。这些包括：
    深度上的不连续
    表面法线方向不连续
    颜色不连续
    亮度不连续
边缘是灰度值不连续的结果，这种不连续常可利用求导数方便地检测到，一般常用一阶和二阶导数来检测边缘。
其中一阶导数的幅度值来检测边缘的存在，幅度峰值一般对应边缘位置。

获取场景中各点相对于摄象机的距离是计算机视觉系统的重要任务之一．场景中各点相对于摄象机的距离可以用深度图(Depth Map)来表示，
即深度图中的每一个像素值表示场景中某一点与摄像机之间的距离．机器视觉系统获取场景深度图技术可分为 被动测距传感 和 主动深度传感 两大类．
被动测距传感是指视觉系统接收来自场景发射或反射的光能量，形成有关 场景光能量分布函数， 即灰度图像，然后在这些图像的基础上恢复场景的深度信息．

最一般的方法是使用两个相隔一定距离的摄像机同时获取场景图像来生成深度图．
与此方法相类似的另一种方法是一个摄象机在不同空间位置上获取两幅或两幅以上图像，通过多幅图像的灰度信息和成象几何来生成深度图．

第3章 实验过程:
(1)得到每一帧的深度图Z，从而得到逆深度图D------------->那么第一个问题，深度图是什么？ 如何求深度图？参考的是谁的方法？
(2)构造能量方程，目标是使得能量和最小
能量函数的唯一参数是Dt, 是逆深度图， 也就是深度图的倒数，


(3)搞清楚能量方程的每一项 
第一项， Photo-consistency term
首先，要清楚 Photo-consistency 是什么?——————参考  https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-31439-6_204
定义: 
Photo-consistency是一种标量函数，用于测量3D重建与一组校准图像的视觉兼容性。
背景: 
多年来，图像自动三维重建一直是核心计算机视觉问题。多视点立体（MVS）是从多个图像重建物体或场景的三维结构的过程[1]。
MVS采用经过校准的照片，其中照相机校准通常通过校准图（例如，棋盘图案）或运动结构算法[2]来实现。原则上，MVS算法如何恢复3D
信息与人类用双眼感知深度的方式相同，即来自对应的三角测量。因此，MVS的关键的第一步是建立跨多个输入图像的特征对应关系，
其中需要强大的机制来评估这些特征对应关系的好处，这是Photo-consistency函数的作用。从某种意义上说，MVS重建过程是在三维
空间中挖掘出二维表面，其中Photo-consistency的值较高。（越高说明越不匹配）
理论和样例：
光照一致性f（p，V）是一种标量函数，用于测量给定三维重建p与一组图像的视觉兼容性。
通常，p是一个三维点（p \ in \ mathbb {R} ^ 3），————（实际中的3D坐标是怎么定义的呢，我的理解是深度）
在3D点p处的简单Photo-consistency函数被定义如下：将p投影到V中的每个可见图像中，并且将它们投影附近的图像纹理的相似度计算为Photo-consistency。
不是比较每个图像中的单个像素颜色，而是比较每个局部图像区域中的一组像素颜色的鲁棒性。


几何相干项的章节太少了
平滑项的内容也比较少
拉普拉斯项的内容也比较少
这三项如果有图就会好办一点。