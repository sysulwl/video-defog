场景深度   								scene depth
立体匹配   								stereo matching 
雾信息	   								fog information
光相干项(照片一致性项)，光密度测量   	photo-consistency term
散射效应   								scattering effects
先验消光拉普拉斯约束   					prior matting Laplacian constraint
细节保持平滑约束						detail-preserving smoothness constraint
MRF框架
辅助变量								auxiliary variables
迭代优化								optimized iteratively 
多视角立体								Multi-view stereo
图像对比度								image contrast

深度平滑								depth smoothness
表面细节								surface details
depth ordering
detail preserving smoothness
airlight-albedo
unsaturated color
multiple depth map approach
multi-view stereo (MVS) vision 
visibility
occlusions
consistency 
sensitivity
geometric coherence term
geometric constraints
characteristic artifacts
energy functions
 depth maps
 shrinking bias
 airlight
 maximizing local contrast
shading 
transmission functions
dark channe
boundary constraint
image fusion
photo-consistency term
  
atmospheric light    是什么  ， alpha是什么？
如何获取alpha ，  atomspheric light A呢。
首先


estTransmission  这个函数，生成了A之后，将im的r g b 三维点除以A， 再简单计算得到alpha矩阵。这就是我们看到的第一张灰度图。

随后，进入拉普拉斯函数的研究。
  
有非常多的专业术语需要我们去搞懂，所以建议还是用英文去学习吧。 
首先，深度图是啥？————是不是我们传统理解的灰度图?
原来，深度就是离我们多远的这个概念，来决定一张图中的先后顺序。深度图像的每个像素点的灰度值可用于表征场景中某一点距离摄像机的远近

边缘检测的目的是标识数字图像中属性显著变化的点。图像属性中的显著变化通常反映了属性的重要变化。这些包括：
    深度上的不连续
    表面法线方向不连续
    颜色不连续
    亮度不连续
边缘是灰度值不连续的结果，这种不连续常可利用求导数方便地检测到，一般常用一阶和二阶导数来检测边缘。
其中一阶导数的幅度值来检测边缘的存在，幅度峰值一般对应边缘位置。

获取场景中各点相对于摄象机的距离是计算机视觉系统的重要任务之一．场景中各点相对于摄象机的距离可以用深度图(Depth Map)来表示，
即深度图中的每一个像素值表示场景中某一点与摄像机之间的距离．机器视觉系统获取场景深度图技术可分为 被动测距传感 和 主动深度传感 两大类．
被动测距传感是指视觉系统接收来自场景发射或反射的光能量，形成有关 场景光能量分布函数， 即灰度图像，然后在这些图像的基础上恢复场景的深度信息．

最一般的方法是使用两个相隔一定距离的摄像机同时获取场景图像来生成深度图．
与此方法相类似的另一种方法是一个摄象机在不同空间位置上获取两幅或两幅以上图像，通过多幅图像的灰度信息和成象几何来生成深度图．

第3章 实验过程:
(1)得到每一帧的深度图Z，从而得到逆深度图D------------->那么第一个问题，深度图是什么？ 如何求深度图？参考的是谁的方法？
(2)构造能量方程，目标是使得能量和最小
能量函数的唯一参数是Dt, 是逆深度图， 也就是深度图的倒数，


(3)搞清楚能量方程的每一项 
第一项， Photo-consistency term
首先，要清楚 Photo-consistency 是什么?——————参考  https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-31439-6_204
定义: 
Photo-consistency是一种标量函数，用于测量3D重建与一组校准图像的视觉兼容性。
背景: 
多年来，图像自动三维重建一直是核心计算机视觉问题。多视点立体（MVS）是从多个图像重建物体或场景的三维结构的过程[1]。
MVS采用经过校准的照片，其中照相机校准通常通过校准图（例如，棋盘图案）或运动结构算法[2]来实现。原则上，MVS算法如何恢复3D
信息与人类用双眼感知深度的方式相同，即来自对应的三角测量。因此，MVS的关键的第一步是建立跨多个输入图像的特征对应关系，
其中需要强大的机制来评估这些特征对应关系的好处，这是Photo-consistency函数的作用。从某种意义上说，MVS重建过程是在三维
空间中挖掘出二维表面，其中Photo-consistency的值较高。（越高说明越不匹配）
理论和样例：
光照一致性f（p，V）是一种标量函数，用于测量给定三维重建p与一组图像的视觉兼容性。
通常，p是一个三维点（p \ in \ mathbb {R} ^ 3），————（实际中的3D坐标是怎么定义的呢，我的理解是深度）
在3D点p处的简单Photo-consistency函数被定义如下：将p投影到V中的每个可见图像中，并且将它们投影附近的图像纹理的相似度计算为Photo-consistency。
不是比较每个图像中的单个像素颜色，而是比较每个局部图像区域中的一组像素颜色的鲁棒性。


几何相干项的章节太少了
平滑项的内容也比较少
拉普拉斯项的内容也比较少
这三项如果有图就会好办一点。

参考论文[43]: 几何相干项:
与典型的多视点立体方法不同，我们的方法不仅强加颜色一致性约束，而且还以统计方式将几何相关性与多个帧明确关联。
将不同视图关联的光照一致性和几何一致性约束组合在全局能量最小化框架中。
它们有助于可靠地减少图像噪声和多帧数据遮挡的影响，从而使我们的优化不受过度平滑或混合伪影的影响。
对于一些使用水平集或可变形多边形网格的MVS方法[9]，[49]，几何相干约束以3D方式并入和制定。
相比之下，我们的方法统计数据术语定义中的光致一致性和几何相干性约束。
通过结合光照一致性和几何一致性约束，我们的数据成本分布变得与众不同，从而使BP优化更加稳定和快速收敛。
让计算机自动建立多幅图像之间的匹配关系（如找到p1点的对应点p2）其实是三维重建最困难的一个问题。图像匹配最常见的做法是基于特征点（如Harris、DoG特征点）的匹配，
此外还有基于直线的匹配，以及基于区域的匹配。
 
空间点P不仅可以通过在左右两张图像上的投影点p1和p2来重建（这称之为双视图几何），类似地，还可通过同时拍3张图像来重建点P，
这就被称为三视图几何。其中三焦张量（Trifocal Tensor）等同于双视图几何中基本矩阵的地位，类推还有四视图几何的四焦张量。
3视图及以上的几何重建统称为多视图立体重建（MVS，Multi-View Stereo）。

平滑项:
Kang和Szeliski [43里面的19]提出通过添加时间平滑项同时优化多个关键帧处的一组深度图。
我们的自适应平滑项在平坦区域中保持平滑，同时保留纹理边缘。
在[43里面的19]中，在数据项之外引入了一种外部平滑项，其功能类似于空间平滑度约束。
在实际情况中，基于逐像素点的匹配代价并不能完全正确地反映两幅图像中两个点匹配的正确性；比如噪声、大范围的相似区域等，其结果是错误匹配的代价常常会小于正确匹配代价，
从而影响算法在该点的深度估计。 并且在全局算法尤其是动态规划算法的框架下，这样的错误匹配代价的估算往往会影响到周围点的深度估计，进而将错误扩散［１］。 因此，在半
全局匹配方法中，必须增加一些额外的平滑约束到能量的定义中，这种约束通常是采用对深度或者灰度的变化的惩罚，以抑制噪声对匹配结果的影响

拉普拉斯平滑项:
雾的出现也开启了丰富重建深度细节的可能性。 为此，我们将拉普拉斯[21]约束作为细节保留平滑项。

3.1  颜色一致性项的构建
3.1.1 评估深度图的颜色一致性
3.1.2 基于散射效应的颜色一致性项的计算

几何相关项的构建

平滑项的构建
朴素的平滑
基于传输的排序约束的平滑

3.4  拉普拉斯平滑项的构建

立体重建深度图的构建
能量方程的构建
能量方程的最优化

3.6  本章小结

vs全部代码排版：1. ctrl+E,D 按住ctrl，相继按下E、D
2. ctrl+K,F 按住ctrl，相继按下K、F

size_t在64位是unsigned long long , 转成int就会有警告
