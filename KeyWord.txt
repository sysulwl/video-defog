场景深度   								scene depth
立体匹配   								stereo matching 
雾信息	   								fog information
光相干项(照片一致性项)，光密度测量   	photo-consistency term
散射效应   								scattering effects
先验消光拉普拉斯约束   					prior matting Laplacian constraint
细节保持平滑约束						detail-preserving smoothness constraint
MRF框架
辅助变量								auxiliary variables
迭代优化								optimized iteratively 
多视角立体								Multi-view stereo
图像对比度								image contrast

深度平滑								depth smoothness
表面细节								surface details
depth ordering
detail preserving smoothness
airlight-albedo
unsaturated color
multiple depth map approach
multi-view stereo (MVS) vision 
visibility
occlusions
consistency 
sensitivity
geometric coherence term
geometric constraints
characteristic artifacts
energy functions
 depth maps
 shrinking bias
 airlight
 maximizing local contrast
shading 
transmission functions
dark channe
boundary constraint
image fusion
photo-consistency term
  
atmospheric light    是什么  ， alpha是什么？
如何获取alpha ，  atomspheric light A呢。
首先


estTransmission  这个函数，生成了A之后，将im的r g b 三维点除以A， 再简单计算得到alpha矩阵。这就是我们看到的第一张灰度图。

随后，进入拉普拉斯函数的研究。
  
有非常多的专业术语需要我们去搞懂，所以建议还是用英文去学习吧。 
首先，深度图是啥？————是不是我们传统理解的灰度图?
原来，深度就是离我们多远的这个概念，来决定一张图中的先后顺序。深度图像的每个像素点的灰度值可用于表征场景中某一点距离摄像机的远近

边缘检测的目的是标识数字图像中属性显著变化的点。图像属性中的显著变化通常反映了属性的重要变化。这些包括：
    深度上的不连续
    表面法线方向不连续
    颜色不连续
    亮度不连续
缘是灰度值不连续的结果，这种不连续常可利用求导数方便地检测到，一般常用一阶和二阶导数来检测边缘。
其中一阶导数的幅度值来检测边缘的存在，幅度峰值一般对应边缘位置。

获取场景中各点相对于摄象机的距离是计算机视觉系统的重要任务之一．场景中各点相对于摄象机的距离可以用深度图(Depth Map)来表示，
即深度图中的每一个像素值表示场景中某一点与摄像机之间的距离．机器视觉系统获取场景深度图技术可分为 被动测距传感 和 主动深度传感 两大类．
被动测距传感是指视觉系统接收来自场景发射或反射的光能量，形成有关 场景光能量分布函数， 即灰度图像，然后在这些图像的基础上恢复场景的深度信息．

最一般的方法是使用两个相隔一定距离的摄像机同时获取场景图像来生成深度图．
与此方法相类似的另一种方法是一个摄象机在不同空间位置上获取两幅或两幅以上图像，通过多幅图像的灰度信息和成象几何来生成深度图．